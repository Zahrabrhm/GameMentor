# ğŸ® GameMentor: AI-Powered Personalized Game Tutorials

[![IEEE CIG 2024](https://img.shields.io/badge/IEEE%20CIG-2024-blue)](https://ieeexplore.ieee.org/document/10613541)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-green.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **GameMentor** is an AI-driven tutorial system that creates personalized learning experiences for video game players. Instead of one-size-fits-all tutorials, GameMentor analyzes your gameplay, identifies your mistakes, and generates customized tutorials that target your specific weaknesses.

## ğŸŒ Live Demo

**[Try the interactive demo â†’](https://Zahrabrhm.github.io/GameMentor/)**

Play Lunar Lander and Super Mario directly in your browser and experience the GameMentor system!

## ğŸ“„ Paper

This repository contains the implementation for our IEEE HSI 2024 paper:

**"GameMentor: Customized Tutorial for Video Games"**

ğŸ“– [Read the paper on IEEE Xplore](https://ieeexplore.ieee.org/document/10613541)

### Citation

```bibtex
@inproceedings{gamementor2024,
  title={GameMentor: Customized Tutorial for Video Games},
  author={[Authors]},
  booktitle={2024 IEEE Conference on Human System Interaction (HSI)},
  year={2024},
  organization={IEEE}
}
```

## ğŸ¯ Overview

Video game tutorials are crucial for player onboarding, but traditional tutorials fail to account for individual skill variations. GameMentor solves this by:

1. **Training an Expert AI Agent** - Using Deep Reinforcement Learning to master the game
2. **Recording Human Gameplay** - Capturing player actions alongside AI recommendations
3. **Identifying Mistakes** - Detecting critical decision points where players made suboptimal choices
4. **Generating Personalized Tutorials** - Creating targeted practice scenarios based on individual weaknesses

![GameMentor Pipeline](docs/images/pipeline.png)

## ğŸš€ Features

- **ğŸ® Lunar Lander** - Classic control problem with Double Deep Q-Network agent
- **ğŸ„ Super Mario Bros** - Platform game with CNN-based DQN agent
- **ğŸ“Š Mistake Analysis** - Automated detection of critical gameplay errors
- **ğŸ“š Personalized Tutorials** - AI demonstrations of correct approach at mistake points
- **ğŸ‹ï¸ Practice Mode** - Recreated scenarios for targeted skill improvement

## ğŸ“ Repository Structure

```
GameMentor/
â”œâ”€â”€ docs/                       # GitHub Pages web demo
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â”œâ”€â”€ lunar-lander.js
â”‚   â”œâ”€â”€ super-mario.js
â”‚   â””â”€â”€ main.js
â”œâ”€â”€ lunar_lander/               # Lunar Lander implementation
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ agent.py           # DQN/Double DQN agent implementation
â”‚   â”‚   â”œâ”€â”€ train.py           # Agent training script
â”‚   â”‚   â”œâ”€â”€ record_gameplay.py # Human gameplay recording
â”‚   â”‚   â”œâ”€â”€ analyze_gameplay.py# Mistake detection
â”‚   â”‚   â”œâ”€â”€ tutorial.py        # Tutorial generation
â”‚   â”‚   â””â”€â”€ practice.py        # Practice mode
â”‚   â”œâ”€â”€ models/                # Pre-trained weights
â”‚   â””â”€â”€ data/                  # Recorded gameplay data
â”œâ”€â”€ super_mario/               # Super Mario implementation
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ mario_agent.py     # CNN-DQN agent and training
â”‚   â”‚   â”œâ”€â”€ record_gameplay.py
â”‚   â”‚   â”œâ”€â”€ analyze_gameplay.py
â”‚   â”‚   â”œâ”€â”€ tutorial.py
â”‚   â”‚   â””â”€â”€ practice.py
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ data/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8+
- CUDA (optional, for GPU acceleration)

### Setup

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/GameMentor.git
cd GameMentor

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# For Super Mario, also install:
pip install gym-super-mario-bros nes-py
```

## ğŸ“– Usage

### Lunar Lander

#### 1. Train the Agent (or use pre-trained weights)

```bash
cd lunar_lander/src
python train.py --episodes 5000 --save-dir ../models
```

#### 2. Record Your Gameplay

```bash
python record_gameplay.py --weights ../models/ddqn_weights.pth --output ../data
```

Use arrow keys to control:
- â†‘ : Fire main engine
- â† : Fire left thruster  
- â†’ : Fire right thruster

#### 3. Analyze Your Performance

```bash
python analyze_gameplay.py --data ../data --threshold 12
```

#### 4. Watch the Tutorial

```bash
python tutorial.py --weights ../models/ddqn_weights.pth --data ../data
```

#### 5. Practice Mode

```bash
python practice.py --weights ../models/ddqn_weights.pth --data ../data
```

### Super Mario Bros

#### 1. Train the Agent

```bash
cd super_mario/src
python mario_agent.py --episodes 50000 --save-dir ../checkpoints
```

#### 2. Record Gameplay & Generate Tutorial

```bash
python record_gameplay.py --checkpoint ../checkpoints/mario_net_X.chkpt --output ../data
python analyze_gameplay.py --data ../data
python tutorial.py --checkpoint ../checkpoints/mario_net_X.chkpt --data ../data
```

## ğŸ§  Technical Details

### Lunar Lander Agent

| Component | Details |
|-----------|---------|
| Algorithm | Double Deep Q-Network (DDQN) |
| State Space | 8-dimensional continuous |
| Action Space | 4 discrete actions |
| Network | MLP: 8 â†’ 128 â†’ 64 â†’ 4 |
| Training | ~2000-5000 episodes |

### Super Mario Agent

| Component | Details |
|-----------|---------|
| Algorithm | DQN with CNN |
| State Space | 84Ã—84Ã—4 grayscale frames |
| Action Space | 7 discrete actions |
| Network | 3 Conv layers + 2 Dense layers |
| Training | ~40000-50000 episodes |

### Mistake Detection

Mistakes are identified at **critical states** where:
- The Q-value difference between best and worst actions exceeds a threshold
- The human action differs from the AI-recommended action

This ensures we focus on moments where decisions actually matter.

## ğŸ“Š Results

Our user studies demonstrate significant improvements with GameMentor:

- **Faster skill acquisition** compared to traditional tutorials
- **Targeted improvement** in specific weak areas
- **Higher engagement** through personalized challenges
- **Better retention** of learned skills

See the [paper](https://ieeexplore.ieee.org/document/10613541) for detailed experimental results.

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI Gym for the Lunar Lander environment
- Nintendo and gym-super-mario-bros for the Super Mario environment
- PyTorch team for the deep learning framework

## ğŸ“¬ Contact

For questions about the paper or implementation, please open an issue or contact the authors.

---

<p align="center">
  <b>â­ If you find this work useful, please consider giving it a star! â­</b>
</p>
